{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K10WeIElOS7E"
      },
      "source": [
        "# Finetuning a pretrained transformer Model for the task of classifying tweets into 4 classes using Huggingface Transformers tools\n",
        "## Adaptation of my project for the Lab Statistical Language Processing course taught at the University of TÃ¼bingen in the Summer Semester of 2024\n",
        "\n",
        "## Honour Code\n",
        "Author: Szymon T. Kossowski \\\n",
        "Honour Code: I pledge that this program represents my own work, and that I have not given or received unauthorized help with this assignment.\n",
        "\n",
        "## Note:\n",
        "I recommend to run this notebook in Google Colab. You can run it locally, but make sure you have CUDA available. Otherwise it's gonna take an eternity or two to run some sections of the code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjUySEhOSz6H"
      },
      "source": [
        "# Notebook setup\n",
        "Installing the packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qM-qAYOeN_HT",
        "outputId": "f8b71e46-4559-4905-e745-1eb53ca11a02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.26.3)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: google in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from google) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->google) (2.6)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.9)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.26.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.9)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate\n",
        "!pip install transformers\n",
        "!pip install google\n",
        "!pip install datasets\n",
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAz0-gUvS8w3"
      },
      "source": [
        "Importing the packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiMnOk5YQ-SK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import collections\n",
        "import numpy as np\n",
        "import evaluate\n",
        "import transformers\n",
        "from google.colab import drive\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akJAsTeTRZQH"
      },
      "source": [
        "Since the training happened in the Google Colab, and this notebook is meant to be run there (it is however, not obligatory), the Google Drive is mounted. Two directories, for models and checkpoints are created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QV18O1v-RQkC",
        "outputId": "25a4bfa7-e656-46be-f760-cbb780810980"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "mkdir: cannot create directory â/content/gdrive/My Drive/classifier-modelâ: File exists\n",
            "mkdir: cannot create directory â/content/gdrive/My Drive/classifier-model/checkpointsâ: File exists\n",
            "mkdir: cannot create directory â/content/gdrive/My Drive/classifier-model/modelsâ: File exists\n",
            "/content/gdrive/My Drive/classifier-model\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/gdrive')\n",
        "\n",
        "output_dir = \"classifier-model\"\n",
        "!mkdir /content/gdrive/My\\ Drive/$output_dir\n",
        "\n",
        "training_checkpoints = \"checkpoints\"\n",
        "models_dir = \"models\"\n",
        "\n",
        "!mkdir /content/gdrive/My\\ Drive/classifier-model/$training_checkpoints\n",
        "!mkdir /content/gdrive/My\\ Drive/classifier-model/$models_dir\n",
        "\n",
        "%cd /content/gdrive/My\\ Drive/classifier-model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjt28NImNLUU"
      },
      "source": [
        "You can, however, use your local memory if you run this notebook locally. Create two directories, for models and checkpoints. The path given here should be adjusted to your needs, so change the `output_dir`, `training_checkpoints` and `models-dir` variable.\n",
        "\n",
        "The code given here is working for Windows users. If you use a Unix-based system, comment out the code for Windows users and enable the code for Unix-based system users."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zqnqdHLNl_Z"
      },
      "outputs": [],
      "source": [
        "# For Windows users\n",
        "output_dir = \"C://path//to//directory//HuggingFace-Classifier-Model//classifier-model\"\n",
        "training_checkpoints = \"C://path//to//directory//HuggingFace-Classifier-Model//classifier-model//checkpoints\"\n",
        "models_dir = \"C://path//to//directory//HuggingFace-Classifier-Model//classifier-model//classifier-model//models\"\n",
        "\n",
        "# For Unix-based system users\n",
        "# output_dir = \"classifier-model\"\n",
        "# !mkdir /c/path/to/directory//huggingface-classifier-model/$output_dir\n",
        "\n",
        "# training_checkpoints = \"checkpoints\"\n",
        "# !mkdir /$output_dir/$training_checkpoints\n",
        "\n",
        "# models_dir = \"models\"\n",
        "# !mkdir /$output_dir/$models_dir\n",
        "\n",
        "%cd \"C://path//to//directory//HuggingFace-Classifier-Model//classifier-model\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c78DKhL0She1"
      },
      "source": [
        "Setting the variable ```device```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SD4Fisq4StwS"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPnWXeXbTANh"
      },
      "source": [
        "# Preparation of the training data\n",
        "Loading the emotion subset of the *tweet_eval* dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKWbZaEpVGgZ",
        "outputId": "020feec2-0b5a-4479-b55b-333e1368cdeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 3257\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 1421\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 374\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "dataset = load_dataset(\"cardiffnlp/tweet_eval\", \"emotion\")\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToTfBROuVxeA"
      },
      "source": [
        "Tokenisation of the entire dataset using the case-insensitive version [distilbert-base-uncased](https://huggingface.co/distilbert-base-uncased) in this lab and in A4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292,
          "referenced_widgets": [
            "9dce45ec36bf4caeb964c9ca9a64ac5a",
            "1a8d15dc5abf4767b53f82606f36fb93",
            "20ad628c8a214473bfde2f3d9d58e7b6",
            "fcd1874429d14a13894d66cbbd8bcf0c",
            "c70f4384ae4a4c878c136d27a93b6741",
            "d2570d0af3da4d06a8a269cca695225a",
            "91954c0c2566438b9787decfa9b4e52d",
            "7dc697e4a84043df93b6f9daa6764c46",
            "6fd6d3aa7a0048c8b028a00c5c6fcd4f",
            "4e401298f9b74abfa0a4cea50eb7c0e5",
            "5d35d710b8b84e5ca8906a00b52915e7"
          ]
        },
        "id": "uT_O3tPGVzxF",
        "outputId": "e843d172-b5a5-487a-ae6b-13c3cc599139"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9dce45ec36bf4caeb964c9ca9a64ac5a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1421 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
            "        num_rows: 3257\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
            "        num_rows: 1421\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
            "        num_rows: 374\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "print(tokenized_datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELickgl0KgVy"
      },
      "source": [
        "Creating small data splits for CPU training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1fq3pArLDZd"
      },
      "outputs": [],
      "source": [
        "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(50))\n",
        "small_dev_dataset = tokenized_datasets[\"validation\"].shuffle(seed=42).select(range(10))\n",
        "small_test_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh41YfvzL4ET"
      },
      "source": [
        "# Pre-training\n",
        "## Loading the pretrained distilbert-base-uncased model\n",
        "The model after the training is supposed to perform classification tasks on a sequence of tokens (here: tweets) as one of several labels. Therefore, the pretrained model is loaded using AutoModelForSequenceClassification. When a pretrained model is loaded for fine-tuning, it needs to know some facts about the training data. In addition to the model name, the following values are passed when loading the pretrained model:\n",
        "\n",
        "num_labels: The number of labels in the training data, which can be retrieved from the training data features\n",
        "\n",
        "label2id: {label:id} dictionary. The list of label names is retrieved from the training data features. Each label is mapped to its index in the list.\n",
        "\n",
        "id2label {id:label} dictionary. Reverse mapping of label2id\n",
        "\n",
        "Providing the label-id mappings will make it easier later, to use the model for inference in the last step. The model will return its predictions as strings (\"anger\", \"joy\",..). If the mappings are not provided, the model returns predictions as \"LABEL_0\", \"LABEL_1\"..., which is inconvenient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EChUupKuMk_U",
        "outputId": "96fc6e19-dcee-4e51-ce48-4aa548f3acf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'anger': 0, 'joy': 1, 'optimism': 2, 'sadness': 3}\n",
            "{0: 'anger', 1: 'joy', 2: 'optimism', 3: 'sadness'}\n"
          ]
        }
      ],
      "source": [
        "# 0: anger\n",
        "# 1: joy\n",
        "# 2: optimism\n",
        "# 3: sadness\n",
        "\n",
        "labels = tokenized_datasets[\"train\"].features[\"label\"].names\n",
        "\n",
        "unique_labels = []\n",
        "\n",
        "for label in labels:\n",
        "  if label not in unique_labels:\n",
        "    unique_labels.append(label)\n",
        "\n",
        "num_labels = len(unique_labels)\n",
        "\n",
        "label2id = {}\n",
        "\n",
        "for i in range(len(unique_labels)):\n",
        "  label2id[unique_labels[i]] = i\n",
        "\n",
        "id2label = {v: k for k, v in label2id.items()}\n",
        "\n",
        "print(label2id)\n",
        "print(id2label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPMVVadnPe7b"
      },
      "source": [
        "Load the pretrained [model](https://huggingface.co/distilbert/distilbert-base-uncased)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoK4snKzPQtX",
        "outputId": "cfa05d15-87a0-4d0b-bf7d-968014ae9b46"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DistilBertForSequenceClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): DistilBertSdpaAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = transformers.AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=num_labels, label2id=label2id, id2label=id2label)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1rS4uRnPotF"
      },
      "source": [
        "## Training arguments\n",
        "\n",
        "In addition to the directory for saving training checkpoints, the following parameters for the training arguments are recommended:\n",
        "\n",
        "`save_total_limit=2`: During training, the model is saved at intervals, according to save_strategy. These models are called checkpoints, and can be used to resume training. Since space is limited, and these checkpoints can fill up the memory rather quickly, we limit their number to 2 (last and best models).\n",
        "\n",
        "`load_best_model_at_end=True`: When training is finished, load the best model. Later, when the model is saved, the best model is saved, not the last trained one.\n",
        "\n",
        "`eval_strategy=\"steps\"`\n",
        "\n",
        "`save_strategy=\"steps\"`\n",
        "\n",
        "`logging_strategy=\"steps\"`\n",
        "\n",
        "Evaluate, save, and log every 500 steps (default value for steps is 500).\n",
        "\n",
        "Alternatively, \"epoch\" as a strategy can be used, just make sure that eval_strategy and save_strategy are the same (or just make them all the same)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQMYVcnaQGsS"
      },
      "outputs": [],
      "source": [
        "training_checkpoints = \"./checkpoints\"\n",
        "training_arguments = transformers.TrainingArguments(\n",
        "    report_to=\"none\",\n",
        "    output_dir=training_checkpoints,\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    eval_strategy=\"steps\",\n",
        "    save_strategy=\"steps\",\n",
        "    logging_strategy=\"steps\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFOCpmrBQ-CQ"
      },
      "source": [
        "## Evaluation Setup\n",
        "Defining the compute_metrics function that will be used for evaluation, both during training\n",
        "and for evaluation on the test set. Since this is a classification task, the F1 score (with\n",
        "macro averaging) is used:\n",
        "`metric = evaluate.load(\"f1\")`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1W2YfLlRGYL"
      },
      "outputs": [],
      "source": [
        "metric = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels, average=\"macro\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f01jBvXRW4Q"
      },
      "source": [
        "## Initialize Trainer and Train\n",
        "When the model is ready for training with the full dataset and there is such a possibility (eg. on Google Colab), a GPU is requested: Runtime -> Change runtime type -> T4 GPU Training for the default 3 epochs will take roughly 2 minutes on a GPU. However, if there is no possibility for GPU training, CPU training should do well, but it is significantly longer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "8pZdnDvfRhgA",
        "outputId": "ba5264ec-41f6-4fcc-e05e-76d6d57c7bdc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1224' max='1224' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1224/1224 08:12, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.262600</td>\n",
              "      <td>1.176944</td>\n",
              "      <td>0.696946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.204100</td>\n",
              "      <td>1.227721</td>\n",
              "      <td>0.713501</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1224, training_loss=0.20278771562513961, metrics={'train_runtime': 492.5295, 'train_samples_per_second': 19.838, 'train_steps_per_second': 2.485, 'total_flos': 1294385117663232.0, 'train_loss': 0.20278771562513961, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "trainset = tokenized_datasets[\"train\"]\n",
        "evalset = tokenized_datasets[\"validation\"]\n",
        "\n",
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    args=training_arguments,\n",
        "    train_dataset=trainset,\n",
        "    eval_dataset=evalset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O655AVWR6GR8"
      },
      "source": [
        "# Saving the Best Model\n",
        "Saving the model to the directory that was created for that purpose when mounting the drive. After the model is saved, it is safe to delete the contents of the directory used for training. It may be necessary to do this to avoid running out of space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "WrlKwbBg6h6A"
      },
      "outputs": [],
      "source": [
        "models_dir = \"./models\"\n",
        "trainer.save_model(models_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ciJ7b1P6p3u"
      },
      "source": [
        "# Loading the saved model\n",
        "If all went well, it should now be able to load the model in the same way the distilbert-base-uncased model was loaded earlier, using AutoModelForSequenceClassification. But this time it is only necessary to provide the model location, since no further training is being done. Then a TextClassificationPipeline is created. The pipeline task is \"sentiment-analysis\", and it will be necessary to provide the distilbert-base-uncased tokenizer as an argument to the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6G6G0JI6zEg",
        "outputId": "2049092e-d9a6-40c3-d6fd-f884e5a97493"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        }
      ],
      "source": [
        "saved_model = transformers.AutoModelForSequenceClassification.from_pretrained(models_dir)\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "analyzer = transformers.pipeline(\"sentiment-analysis\", model=saved_model, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3bgvfge7OuB"
      },
      "source": [
        "# Using the saved model for inference\n",
        "Using the pipeline created in the previous step to classify some tweets (at least 15). Tweets from the test set for this part can be used. For each tweet, the modelâs prediction, the modelâs confidence score, and the tweet are printed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRyJh7YZ7TtJ",
        "outputId": "effcb5c2-67f9-48e8-f0d3-8c0c5bdb9e06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet: @user @user Why is this even a thing? #lost\n",
            "Prediction: sadness\n",
            "Confidence: 0.9965887069702148\n",
            "Tweet: who knew magnus bane with teary eyes and trembling lips would be my downfall\n",
            "Prediction: anger\n",
            "Confidence: 0.9986338019371033\n",
            "Tweet: This the way I rage, \\n\\non sum wopstar shit â­ï¸\n",
            "Prediction: anger\n",
            "Confidence: 0.999642014503479\n",
            "Tweet: Happy birthdayððâ¤ï¸ð @user I love and miss you bunches &amp; hope you have an amazing day beautiful!!ðð¸ðð\n",
            "Prediction: joy\n",
            "Confidence: 0.9995049238204956\n",
            "Tweet: Great game of tennis this one ðð»ðð»ð¾ #nervous\n",
            "Prediction: joy\n",
            "Confidence: 0.9964063763618469\n",
            "Tweet: @user The little details in life can build up to things that could affect you negatively and eventually make unhappy and lonely.\n",
            "Prediction: sadness\n",
            "Confidence: 0.9990500807762146\n",
            "Tweet: @user Iâm glad to hear that, Kara. Donât hesitate to get in touch again if you need to! Cheryl\n",
            "Prediction: joy\n",
            "Confidence: 0.990203857421875\n",
            "Tweet: Gorkas is angrily unhinged, &amp;lecturing CNN on what?they should cover demanding they go after Hillary Clinton instead of Trump.\n",
            "Prediction: anger\n",
            "Confidence: 0.9996374845504761\n",
            "Tweet: Happy 12th birthday to my Neopet! #retro\\nHappy 75th birthday, Harrison Ford! #legendary\\nHappy 80th birthday, Krispy Kreme! #delicious\n",
            "Prediction: joy\n",
            "Confidence: 0.9995343685150146\n",
            "Tweet: Saddest part about messing up both my legs/ankles? I miss heels. Being a 7fg giant was fun. #sadness\n",
            "Prediction: sadness\n",
            "Confidence: 0.9993137121200562\n",
            "Tweet: Mayweather's trash talking is on par with Nate Diaz #terrible would love to see McGregor KO him #MayweatherVsMcGregor\n",
            "Prediction: anger\n",
            "Confidence: 0.9994798302650452\n",
            "Tweet: @user no offense but one of my friend watches you and calls you his 'Synpie' which i have no idea why but, he watches your videos\n",
            "Prediction: anger\n",
            "Confidence: 0.9953902959823608\n",
            "Tweet: Nice one #EE  so much for data protection, not impressed that you can talk to someone the opposite sex who guessed my password,\n",
            "Prediction: anger\n",
            "Confidence: 0.7909303307533264\n",
            "Tweet: May or may not have just pulled the legal card on these folks. #irritated\n",
            "Prediction: anger\n",
            "Confidence: 0.9995936751365662\n",
            "Tweet: When one door closes another one opens #opportunity #growth #optimism\n",
            "Prediction: optimism\n",
            "Confidence: 0.9977009892463684\n"
          ]
        }
      ],
      "source": [
        "tweets = dataset[\"test\"].shuffle(seed=42).select(range(15))[\"text\"]\n",
        "for tweet in tweets:\n",
        "  analysis = analyzer(tweet)\n",
        "  print(f\"Tweet: {tweet}\")\n",
        "  print(f\"Prediction: {analysis[0]['label']}\")\n",
        "  print(f\"Confidence: {analysis[0]['score']}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1a8d15dc5abf4767b53f82606f36fb93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2570d0af3da4d06a8a269cca695225a",
            "placeholder": "â",
            "style": "IPY_MODEL_91954c0c2566438b9787decfa9b4e52d",
            "value": "Map:â100%"
          }
        },
        "20ad628c8a214473bfde2f3d9d58e7b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dc697e4a84043df93b6f9daa6764c46",
            "max": 1421,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6fd6d3aa7a0048c8b028a00c5c6fcd4f",
            "value": 1421
          }
        },
        "4e401298f9b74abfa0a4cea50eb7c0e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d35d710b8b84e5ca8906a00b52915e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fd6d3aa7a0048c8b028a00c5c6fcd4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7dc697e4a84043df93b6f9daa6764c46": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91954c0c2566438b9787decfa9b4e52d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9dce45ec36bf4caeb964c9ca9a64ac5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a8d15dc5abf4767b53f82606f36fb93",
              "IPY_MODEL_20ad628c8a214473bfde2f3d9d58e7b6",
              "IPY_MODEL_fcd1874429d14a13894d66cbbd8bcf0c"
            ],
            "layout": "IPY_MODEL_c70f4384ae4a4c878c136d27a93b6741"
          }
        },
        "c70f4384ae4a4c878c136d27a93b6741": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2570d0af3da4d06a8a269cca695225a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcd1874429d14a13894d66cbbd8bcf0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e401298f9b74abfa0a4cea50eb7c0e5",
            "placeholder": "â",
            "style": "IPY_MODEL_5d35d710b8b84e5ca8906a00b52915e7",
            "value": "â1421/1421â[00:00&lt;00:00,â2131.80âexamples/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}